For all plots:

I = 10 # photons/laser pulse
QE = .30; #Quantum efficiency
DC = 1e-5;  # dark counts per exposure
amb = 1e-5; # ambient light


For smoothed.png

1000 trials, prior sum_squares(r[:1] - r[:-1]), gamma 5e5
Gaussian intensities
No jitter

For jitter.png

25000 trials, random folded normal intensities
No prior.
jitter_probs = [0.1, 0.5, 0.25, 0.1, 0.05]
jitter_vals = [-5, 0, 5, 10, 15]

For frames.png

5000 shots

Cornell data
jitter_probs = [0.1, 0.6, 0.2, 0.1]
jitter_vals = [-1, 0, 1, 2]
gamma = 1e3, prior tv(r)

||r_star - r_true||_2^2 =  70.5893745263
||r_c - r_true||_2^2 =  109.318242471
MSE ratio =  0.645723649874

With L1 trend filter.
||r_star - r_true||_2^2 =  70.5177582052
||r_c - r_true||_2^2 =  109.318242471
MSE ratio =  0.645068532124

[(158,168,'Large box'), (97,200, 'Small box')]

Gated_cornell.npy: Gates cover 10 bins. Normalize intensity profile for each pixel.
Naive but converges to correct answer with large number of shots.

Stuff for grant:

Cornell data from T=0:150

10000 shots

New frames.png
jitter_probs = [0.05, 0.8, 0.15]
jitter_vals = [-1, 0, 1]

pixels (160,170,'Large box'), (195,97, 'Small box')
pixel [(158,168,'Large box'), (197,97, 'Small box')]

prior = (.01*norm(r,1) + L1TV(on 5x5 patch))*.05*10000
||r_star - r_true||_2^2 =  43.0567957738
||r_c - r_true||_2^2 =  54.7148918061
MSE ratio =  0.786930109017

no jitter

5000 shots
prior 10*5000*sum_squares(r[1:] - r[:-1])


###########################

10/11

For high-noise-single-reflector.png and low-noise-single-reflector.png
commit a58d064a7bf3e330382a6c3eeb1b4b1b201031ed
From superres_sim.py, 1000 reps
Fixed Gaussian fit (was wrong before)
